{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1qIoBls7gHskdaNJOlXsiahTG6Xb7Kz_h",
      "authorship_tag": "ABX9TyMJtCmW0XHeD4tT7sMZbUwu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhairyakumarshah/Medical_Image/blob/main/Image_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pandas opencv-python-headless scikit-learn"
      ],
      "metadata": {
        "id": "ZdFkbI9qa1sk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "-h3r9BRmbIs7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update this based on your dataset location in Drive\n",
        "image_root = '/content/drive/MyDrive/UW GI classification/train'  # Folder containing all case folders\n",
        "csv_path = '/content/drive/MyDrive/UW GI classification/train.csv'  # Path to train.csv\n"
      ],
      "metadata": {
        "id": "2qlDIrrgb5us"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Load the CSV and generate image paths\n",
        "df = pd.read_csv(csv_path)\n",
        "df['segmentation'] = df.segmentation.fillna('')  # fill empty masks\n",
        "df['rle_len'] = df.segmentation.map(len)  # optional: length of RLE\n",
        "df['empty'] = (df.rle_len == 0)  # mark empty masks"
      ],
      "metadata": {
        "id": "xFDR84_-cAuE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract case, day, and slice from `id`\n",
        "def extract_parts(row):\n",
        "    parts = row['id'].split('_')\n",
        "    return pd.Series({\n",
        "        'case': parts[0],\n",
        "        'day': parts[1],\n",
        "        'slice': int(parts[3])\n",
        "    })\n",
        "\n",
        "df = df.join(df.apply(extract_parts, axis=1))\n"
      ],
      "metadata": {
        "id": "68_yrhOadKZN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct image path\n",
        "def build_image_path(row):\n",
        "    return os.path.join(\n",
        "        image_root,\n",
        "        f\"{row['case']}\",\n",
        "        f\"{row['case']}_{row['day']}\",\n",
        "        \"scans\",\n",
        "        f\"slice_{row['slice']:04d}_266_266_1.50_1.50.png\"\n",
        "    )\n",
        "\n",
        "df['image_path'] = df.apply(build_image_path, axis=1)\n"
      ],
      "metadata": {
        "id": "IzM9MT4QdPxq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter one image per ID for classification (can choose first by group)\n",
        "df_class = df.groupby(['id', 'class']).first().reset_index()"
      ],
      "metadata": {
        "id": "hXdlM03ye8rH"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "image_folder = \"/content/drive/MyDrive/UW GI classification/train/case101/case101_day20/scans/\"\n",
        "image_files = [f for f in os.listdir(image_folder) if f.endswith('.png')]\n",
        "\n",
        "# Print filenames to inspect\n",
        "for image_file in image_files[:5]:  # Checking first 5 images\n",
        "    print(f\"Filename: {image_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fR-x9MAsfi3S",
        "outputId": "e62677dc-df46-4a44-d13f-e6246be222b4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filename: slice_0030_266_266_1.50_1.50.png\n",
            "Filename: slice_0001_266_266_1.50_1.50.png\n",
            "Filename: slice_0008_266_266_1.50_1.50.png\n",
            "Filename: slice_0005_266_266_1.50_1.50.png\n",
            "Filename: slice_0002_266_266_1.50_1.50.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the load_and_normalize function to handle grayscale images\n",
        "def load_and_normalize_image(image_path):\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Read as grayscale\n",
        "    if img is None:\n",
        "        return None\n",
        "    img = cv2.resize(img, (224, 224))  # Resize the image\n",
        "    img = np.expand_dims(img, axis=-1)  # Add a channel dimension (e.g., for grayscale)\n",
        "    img = img / 255.0  # Normalize the image\n",
        "    return img\n",
        "\n",
        "# Load and normalize a few sample images\n",
        "sample_images = [load_and_normalize_image(image_paths[i]) for i in range(5)]\n",
        "\n",
        "# Display the images\n",
        "fig, axes = plt.subplots(1, 5, figsize=(15, 5))\n",
        "for i, ax in enumerate(axes):\n",
        "    if sample_images[i] is not None:\n",
        "        ax.imshow(sample_images[i].squeeze(), cmap='gray')  # Display grayscale image\n",
        "        ax.axis('off')\n",
        "    else:\n",
        "        ax.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "AUMDO4Pofwt-",
        "outputId": "7d6b726e-6337-4858-c9f2-a4fdbf54e757"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "\n",
        "def extract_metadata_from_filename(filename):\n",
        "    # Try a more flexible regex to handle the filename format\n",
        "    match = re.match(r\"slice_(\\d+)_(\\d+)_(\\d+)_(\\d+\\.\\d+)_(\\d+\\.\\d+)\\.png\", filename)\n",
        "    if match:\n",
        "        slice_number = int(match.group(1))  # slice number\n",
        "        width = int(match.group(2))         # image width in pixels\n",
        "        height = int(match.group(3))        # image height in pixels\n",
        "        pixel_spacing_width = float(match.group(4))  # pixel spacing (width) in mm\n",
        "        pixel_spacing_height = float(match.group(5)) # pixel spacing (height) in mm\n",
        "\n",
        "        return slice_number, width, height, pixel_spacing_width, pixel_spacing_height\n",
        "    else:\n",
        "        print(f\"Regex match failed for filename: {filename}\")\n",
        "        return None\n",
        "\n",
        "# Folder path where images are stored\n",
        "image_folder = \"/content/drive/MyDrive/UW GI classification/train/case101/case101_day20/scans/\"\n",
        "image_files = [f for f in os.listdir(image_folder) if f.endswith('.png')]\n",
        "\n",
        "# Extract metadata for the first 5 images\n",
        "for image_file in image_files[:5]:  # Checking first 5 images\n",
        "    metadata = extract_metadata_from_filename(image_file)\n",
        "    if metadata:\n",
        "        print(f\"File: {image_file} -> Slice: {metadata[0]}, Resolution: {metadata[1]}x{metadata[2]}, Pixel Spacing: {metadata[3]}x{metadata[4]} mm\")\n",
        "    else:\n",
        "        print(f\"Could not extract metadata for file: {image_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZqqZ488grHz",
        "outputId": "78f298f7-a204-4c3a-bb87-4df2962f2919"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File: slice_0030_266_266_1.50_1.50.png -> Slice: 30, Resolution: 266x266, Pixel Spacing: 1.5x1.5 mm\n",
            "File: slice_0001_266_266_1.50_1.50.png -> Slice: 1, Resolution: 266x266, Pixel Spacing: 1.5x1.5 mm\n",
            "File: slice_0008_266_266_1.50_1.50.png -> Slice: 8, Resolution: 266x266, Pixel Spacing: 1.5x1.5 mm\n",
            "File: slice_0005_266_266_1.50_1.50.png -> Slice: 5, Resolution: 266x266, Pixel Spacing: 1.5x1.5 mm\n",
            "File: slice_0002_266_266_1.50_1.50.png -> Slice: 2, Resolution: 266x266, Pixel Spacing: 1.5x1.5 mm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Define the function to extract metadata from filenames\n",
        "def extract_metadata_from_filename(filename):\n",
        "    import re\n",
        "    pattern = r'slice_(\\d+)_\\d+_\\d+_(\\d+\\.\\d+)_'\n",
        "    match = re.match(pattern, filename)\n",
        "    if match:\n",
        "        slice_number = int(match.group(1))\n",
        "        pixel_spacing = float(match.group(2))\n",
        "        return slice_number, pixel_spacing\n",
        "    return None, None\n",
        "\n",
        "# Step 2: Load CSV and image paths\n",
        "train_csv_path = '/content/drive/MyDrive/UW GI classification/train.csv'\n",
        "df = pd.read_csv(train_csv_path)\n",
        "\n",
        "# Ensure segmentation is filled (adjust if needed)\n",
        "df['segmentation'] = df.segmentation.fillna('')\n",
        "\n",
        "# Step 3: Prepare image paths\n",
        "image_dir = \"/content/drive/MyDrive/UW GI classification/train\"\n",
        "image_paths = []\n",
        "\n",
        "# Loop to get image paths from the directory\n",
        "for case_folder in os.listdir(image_dir):\n",
        "    case_path = os.path.join(image_dir, case_folder)\n",
        "    if os.path.isdir(case_path):\n",
        "        for day_folder in os.listdir(case_path):\n",
        "            day_path = os.path.join(case_path, day_folder, 'scans')\n",
        "            if os.path.isdir(day_path):\n",
        "                for img_file in os.listdir(day_path):\n",
        "                    img_path = os.path.join(day_path, img_file)\n",
        "                    if img_path.endswith('.png'):\n",
        "                        image_paths.append(img_path)\n",
        "\n",
        "# Step 4: Load and preprocess images\n",
        "images = []\n",
        "labels = []  # You'll need to create labels from your data, this is just an example\n",
        "for img_path in image_paths:\n",
        "    # Extract metadata\n",
        "    slice_number, pixel_spacing = extract_metadata_from_filename(img_path)\n",
        "\n",
        "    if slice_number is not None:\n",
        "        # Load image\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.resize(img, (224, 224))  # Resize to ResNet50 input size\n",
        "        img = img / 255.0  # Normalize image\n",
        "        images.append(img)\n",
        "\n",
        "        # Create dummy label (Replace with actual labels from your CSV)\n",
        "        labels.append(slice_number)  # Replace this with the actual class if available"
      ],
      "metadata": {
        "id": "eT4WmyRyhQS-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# Function to show a sample of images\n",
        "def display_sample_images(image_paths, num_images=5):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "\n",
        "    # Select a few images to display\n",
        "    for i, img_path in enumerate(image_paths[:num_images]):\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB\n",
        "\n",
        "        plt.subplot(1, num_images, i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"Image {i + 1}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Call the function to display images\n",
        "display_sample_images(image_paths, num_images=5)  # Adjust num_images to display more/less\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "iuT9WjAthScl",
        "outputId": "914fe2f7-8111-446f-f298-21548e84fca5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Function to normalize and show images\n",
        "def normalize_and_display_images(image_paths, num_images=5):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "\n",
        "    # Select a few images to display\n",
        "    for i, img_path in enumerate(image_paths[:num_images]):\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        # Normalize the image (scale pixel values to 0-1)\n",
        "        img_normalized = img / 255.0\n",
        "\n",
        "        # Convert to RGB (since OpenCV loads images in BGR)\n",
        "        img_normalized_rgb = cv2.cvtColor(img_normalized, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        plt.subplot(1, num_images, i + 1)\n",
        "        plt.imshow(img_normalized_rgb)\n",
        "        plt.title(f\"Normalized Image {i + 1}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Call the function to display normalized images\n",
        "normalize_and_display_images(image_paths, num_images=5)  # Adjust num_images to display more/less\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "MIG6LusUhnEs",
        "outputId": "85e7d0f6-f500-4946-fe0c-1740be5a34d0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "OpenCV(4.11.0) /io/opencv/modules/imgproc/src/color.simd_helpers.hpp:94: error: (-2:Unspecified error) in function 'cv::impl::{anonymous}::CvtHelper<VScn, VDcn, VDepth, sizePolicy>::CvtHelper(cv::InputArray, cv::OutputArray, int) [with VScn = cv::impl::{anonymous}::Set<3, 4>; VDcn = cv::impl::{anonymous}::Set<3, 4>; VDepth = cv::impl::{anonymous}::Set<0, 2, 5>; cv::impl::{anonymous}::SizePolicy sizePolicy = cv::impl::<unnamed>::NONE; cv::InputArray = const cv::_InputArray&; cv::OutputArray = const cv::_OutputArray&]'\n> Unsupported depth of input image:\n>     'VDepth::contains(depth)'\n> where\n>     'depth' is 6 (CV_64F)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-126d253a1b0a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Call the function to display normalized images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mnormalize_and_display_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Adjust num_images to display more/less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-32-126d253a1b0a>\u001b[0m in \u001b[0;36mnormalize_and_display_images\u001b[0;34m(image_paths, num_images)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Convert to RGB (since OpenCV loads images in BGR)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mimg_normalized_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_normalized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.11.0) /io/opencv/modules/imgproc/src/color.simd_helpers.hpp:94: error: (-2:Unspecified error) in function 'cv::impl::{anonymous}::CvtHelper<VScn, VDcn, VDepth, sizePolicy>::CvtHelper(cv::InputArray, cv::OutputArray, int) [with VScn = cv::impl::{anonymous}::Set<3, 4>; VDcn = cv::impl::{anonymous}::Set<3, 4>; VDepth = cv::impl::{anonymous}::Set<0, 2, 5>; cv::impl::{anonymous}::SizePolicy sizePolicy = cv::impl::<unnamed>::NONE; cv::InputArray = const cv::_InputArray&; cv::OutputArray = const cv::_OutputArray&]'\n> Unsupported depth of input image:\n>     'VDepth::contains(depth)'\n> where\n>     'depth' is 6 (CV_64F)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}